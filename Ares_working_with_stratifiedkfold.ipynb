{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdawcMiZElhlFZB60VCTFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/octpsmon/BUS_segmentation_machine_learning_semantic_segmentation/blob/main/Ares_working_with_stratifiedkfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLy0uNFVkPkB"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "#estimated training time 5-6 hrs\n",
        "print(\"Code started\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset, SubsetRandomSampler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from distutils.dir_util import copy_tree\n",
        "import sys\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logging.basicConfig(filename='logname.log',\n",
        "                    filemode='a',\n",
        "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
        "                    datefmt='%H:%M:%S',\n",
        "                    level=logging.DEBUG)\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.info(\"Sanity check\")\n",
        "memfs_path = os.environ.get(\"MEMFS\")\n",
        "logger.info(memfs_path)\n",
        "\n",
        "# # Define the data directory\n",
        "# data_dir = '/content/drive/MyDrive/cropped_testexamples/'\n",
        "\n",
        "# Define the data directory\n",
        "data_dir = '/net/ascratch/people/plgmnkpltrz/pretrainedResNet18/cropped'\n",
        "copy_tree(data_dir,memfs_path)\n",
        "logger.info(os.listdir(memfs_path))\n",
        "data_dir = memfs_path\n",
        "\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['_0_grade', '_1_grade', '_2_grade', '_3_grade', '_4_grade']\n",
        "logger.info(device)\n",
        "# Define the transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),  # Resize the images to 224x224\n",
        "    transforms.ToTensor(),   # Convert images to tensors\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # Normalize image channels\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "labels = dataset.targets  # Get the labels for the dataset\n",
        "\n",
        "# Define the k-fold cross-validation parameters\n",
        "num_folds = 10\n",
        "# kfold = KFold(n_splits=num_folds, shuffle=True, random_state=123)\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=123)\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "# Define data augmentation configuration\n",
        "data_augmentation = {\n",
        "    '_0_grade': 39,  # Augment _0_grade class to have 39 images\n",
        "    '_1_grade': 45,  # Augment _1_grade class to have 45 images\n",
        "    '_2_grade': 51,  # Augment _2_grade class to have 51 images\n",
        "    '_3_grade': 48,  # Augment _3_grade class to have 48 images\n",
        "    '_4_grade': 44   # Augment _4_grade class to have 44 images\n",
        "}\n",
        "\n",
        "# Define the ResNet-18 model\n",
        "resnet_model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Unfreeze additional layers\n",
        "for param in resnet_model.layer3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in resnet_model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace the last fully connected layer with a new untrained one\n",
        "num_features = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(num_features, len(class_names))\n",
        "resnet_model = resnet_model.to(device)\n",
        "dataset_indexes = list(range(len(dataset)))\n",
        "\n",
        "# Lists to store accuracy results for each fold\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "# # Perform k-fold cross-validation\n",
        "# for fold, (train_indexes, val_indexes) in enumerate(kfold.split(dataset_indexes)):\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_indexes, val_indexes) in enumerate(kfold.split(dataset_indexes, labels)):\n",
        "    train_sub = [dataset[n] for n in train_indexes]\n",
        "    val_sub= [dataset[p] for p in val_indexes]\n",
        "\n",
        "    train_images, train_labels = zip(*train_sub)\n",
        "    val_images, val_labels = zip(*val_sub)\n",
        "\n",
        "    train_images = torch.stack(train_images)\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    val_images = torch.stack(val_images)\n",
        "    val_labels = torch.tensor(val_labels)\n",
        "\n",
        "    train_subset = torch.torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "    val_subset = torch.torch.utils.data.TensorDataset(val_images, val_labels)\n",
        "    logger.info(\"Created subsets\")\n",
        "\n",
        "    print(f\"Fold: {fold + 1}\")\n",
        "\n",
        "    # Print the number of images for each class before augmentation\n",
        "    print(\"Number of images per class before augmentation:\")\n",
        "    for class_name in class_names:\n",
        "        logger.info(\"Augmenting\")\n",
        "        class_indices = [idx for idx, (image, label) in enumerate(train_subset) if class_names[label] == class_name]\n",
        "        print(f\"{class_name}: {len(class_indices)}\")\n",
        "\n",
        "# Apply data augmentation to specific classes\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "augmented_data = []\n",
        "for class_name, augment_times in data_augmentation.items():\n",
        "    class_indices = [idx for idx, (image, label) in enumerate(train_subset) if class_names[label] == class_name]\n",
        "    if augment_times > 0:\n",
        "        for idx in class_indices:\n",
        "            image, label = train_subset[idx]\n",
        "            augmented_data.append((image, label))  # Add the original image once\n",
        "            if class_name != '_2_grade':\n",
        "                augment_times -= 1  # Adjust the number of remaining augmentations for this class\n",
        "                augmented_data.append((image, label))  # Add the original image once again\n",
        "                for _ in range(augment_times):\n",
        "                    augmented_image = transforms.RandomRotation(90)(image)\n",
        "                    augmented_data.append((augmented_image, label))\n",
        "    logger.info(\"Getting past augmentation\")\n",
        "\n",
        "    # Convert augmented images and labels to tensors\n",
        "    augmented_images = torch.stack([data[0] for data in augmented_data])\n",
        "    augmented_labels = torch.tensor([data[1] for data in augmented_data])\n",
        "\n",
        "    # Create a new augmented subset\n",
        "    augmented_subset = torch.utils.data.TensorDataset(augmented_images, augmented_labels)\n",
        "\n",
        "    # Combine the original train subset and augmented subset\n",
        "    train_subset = torch.utils.data.ConcatDataset([train_subset, augmented_subset])\n",
        "\n",
        "    # Print the number of images for each class after augmentation\n",
        "    print(\"Number of images per class after augmentation:\")\n",
        "    for class_name in class_names:\n",
        "        class_indices = [idx for idx, (image, label) in enumerate(train_subset) if class_names[label] == class_name]\n",
        "        print(f\"{class_name}: {len(class_indices)}\")\n",
        "    print()\n",
        "\n",
        "    def custom_collate(batch):\n",
        "        images, labels = zip(*batch)\n",
        "        images = torch.stack(images)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "        return images, labels\n",
        "\n",
        "    # Create data loaders for training and validation\n",
        "    batch_size = 20\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
        "                                                   collate_fn=custom_collate)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Compile and train the model on the current fold\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(resnet_model.fc.parameters(), lr=0.0001)  # Specify a lower learning rate\n",
        "\n",
        "    # Variables to track best model and accuracies\n",
        "    best_train_acc = 0.0\n",
        "    best_val_acc = 0.0\n",
        "    best_model = None\n",
        "    train_preds = []\n",
        "    val_preds = []\n",
        "    train_true_labels = []\n",
        "    val_true_labels = []\n",
        "\n",
        "    logging.info(\"Getting here to the training part\")\n",
        "\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Training loop for each fold\n",
        "    for epoch in range(50):\n",
        "        # Training phase\n",
        "        resnet_model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = resnet_model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            # Store predictions and true labels for calculating confusion matrix\n",
        "            \n",
        "        # Calculate accuracy and loss for the training set\n",
        "        train_acc = 100. * correct / total\n",
        "        train_loss /= len(train_dataloader)\n",
        "\n",
        "        # Validation phase\n",
        "        resnet_model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_dataloader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = resnet_model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Store predictions and true labels for calculating confusion matrix\n",
        "                \n",
        "\n",
        "        # Calculate accuracy and loss for the validation set\n",
        "        val_acc = 100. * correct / total\n",
        "        val_loss /= len(val_dataloader)\n",
        "\n",
        "        # Print training and validation accuracy for each fold\n",
        "        print(f\"Fold: {fold + 1}, Epoch: {epoch + 1}, Train Accuracy: {train_acc:.2f}%, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if val_acc > best_val_acc:\n",
        "            best_train_acc = train_acc\n",
        "            best_val_acc = val_acc\n",
        "            best_model = resnet_model.state_dict()\n",
        "\n",
        "            # Save the best model\n",
        "            torch.save(best_model, \"transfer_learn_ResNet18_best_model.pth\")\n",
        "    \n",
        "    # Calculate confusion matrices\n",
        "    resnet_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = resnet_model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_preds.extend(predicted.tolist())\n",
        "            train_true_labels.extend(labels.tolist())\n",
        "\n",
        "        for images_val, labels_val in val_dataloader:\n",
        "            images_val = images_val.to(device)\n",
        "            labels_val = labels_val.to(device)\n",
        "            outputs_val = resnet_model(images_val)\n",
        "            _, predicted_val = outputs_val.max(1)\n",
        "            val_preds.extend(predicted_val.tolist())\n",
        "            val_true_labels.extend(labels_val.tolist())\n",
        "    train_confusion_matrix = confusion_matrix(train_true_labels, train_preds)\n",
        "    val_confusion_matrix = confusion_matrix(val_true_labels, val_preds)\n",
        "\n",
        "    print(train_confusion_matrix)\n",
        "    print(val_confusion_matrix)\n",
        "\n",
        "    # Append accuracy results for each fold\n",
        "    results[f\"fold {fold + 1} train accuracy\"] = best_train_acc\n",
        "    results[f\"fold {fold + 1} val accuracy\"] = best_val_acc\n",
        "\n",
        "# Calculate mean training and validation accuracy from folds\n",
        "mean_train_acc = np.mean([results[f\"fold {i + 1} train accuracy\"] for i in range(num_folds)])\n",
        "mean_val_acc = np.mean([results[f\"fold {i + 1} val accuracy\"] for i in range(num_folds)])\n",
        "\n",
        "# Calculate standard deviation of training and validation accuracy from folds\n",
        "std_train_acc = np.std([results[f\"fold {i + 1} train accuracy\"] for i in range(num_folds)])\n",
        "std_val_acc = np.std([results[f\"fold {i + 1} val accuracy\"] for i in range(num_folds)])\n",
        "\n",
        "# Print best accuracy obtained within folds on train and validation datasets\n",
        "print(\"Results from all folds:\")\n",
        "for i in range(num_folds):\n",
        "    print(f\"Fold {i + 1} Train Accuracy: {results[f'fold {i + 1} train accuracy']:.2f}%\")\n",
        "    print(f\"Fold {i + 1} Val Accuracy: {results[f'fold {i + 1} val accuracy']:.2f}%\")\n",
        "\n",
        "# Print mean and standard deviation of training and validation accuracy\n",
        "print(\"Mean Training Accuracy: {:.2f}% (Std: {:.2f})\".format(mean_train_acc, std_train_acc))\n",
        "print(\"Mean Validation Accuracy: {:.2f}% (Std: {:.2f})\".format(mean_val_acc, std_val_acc))"
      ]
    }
  ]
}